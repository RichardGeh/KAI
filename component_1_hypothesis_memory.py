"""
component_1_hypothesis_memory.py

Hypothesis storage and retrieval for abductive reasoning.

This module handles:
- Hypothesis storage (abductive reasoning outputs)
- Hypothesis-to-observation/concept linking
- Hypothesis queries (by topic, strategy, confidence)
- Best hypothesis retrieval
- Natural language explanation generation

Abductive Reasoning Memory:
    Stores hypotheses generated by the abductive reasoning engine (component_14).
    Each Hypothesis explains observed phenomena through different strategies
    (template, analogy, causal chain). Includes multi-criteria scoring
    (coverage, simplicity, coherence, specificity) and detailed reasoning traces.

Architecture:
    - Uses Neo4jSessionMixin for thread-safe database access
    - Neo4j Schema:
        * Hypothesis nodes (explanations with scores)
        * EXPLAINS: Hypothesis -> Observation
        * ABOUT: Hypothesis -> Konzept
    - Supports filtering by confidence, strategy, topic
    - Stores abduced facts as JSON arrays

Thread Safety:
    All database operations are thread-safe via Neo4jSessionMixin._safe_run()
    with RLock synchronization.

Dependencies:
    - infrastructure/neo4j_session_mixin.py: Session management
    - component_15_logging_config.py: Structured logging
    - kai_exceptions.py: Exception hierarchy

Usage:
    from neo4j import Driver
    from component_1_hypothesis_memory import HypothesisMemory

    driver = Driver("bolt://localhost:7687", auth=("neo4j", "password"))
    memory = HypothesisMemory(driver)

    # Store hypothesis
    hyp_id = "uuid-1234"
    memory.store_hypothesis(
        hypothesis_id=hyp_id,
        explanation="Based on X, Y follows",
        observations=["obs1", "obs2"],
        strategy="template",
        confidence=0.87,
        scores={"coverage": 0.9, "simplicity": 0.85},
        abduced_facts=[{"subject": "X", "relation": "CAUSES", "object": "Y"}]
    )

    # Link to concepts
    memory.link_hypothesis_to_concepts(hyp_id, ["concept1", "concept2"], ensure_wort_callback)

    # Query hypotheses
    hypotheses = memory.query_hypotheses_about("concept1", min_confidence=0.8)
    best = memory.get_best_hypothesis_for("concept1")

    # Generate explanation
    explanation = memory.explain_hypothesis(hyp_id)

Note: Follows CLAUDE.md standards - NO cp1252-unsafe Unicode, structured logging,
      comprehensive error handling, thread safety.
"""

import json
from typing import Any, Callable, Dict, List, Optional

from neo4j import Driver

from component_15_logging_config import get_logger
from infrastructure.neo4j_session_mixin import Neo4jSessionMixin

logger = get_logger(__name__)


class HypothesisMemory(Neo4jSessionMixin):
    """
    Hypothesis storage and retrieval for abductive reasoning.

    Provides storage and querying of hypotheses generated by abductive reasoning
    with multi-criteria scoring and provenance tracking.

    Attributes:
        driver: Neo4j driver instance (inherited from Neo4jSessionMixin)

    Thread Safety:
        All methods are thread-safe via Neo4jSessionMixin._safe_run()

    Example:
        memory = HypothesisMemory(driver)

        # Store hypothesis
        hyp_id = memory.store_hypothesis(...)

        # Link to observations and concepts
        memory.link_hypothesis_to_observations(hyp_id, ["obs1", "obs2"])
        memory.link_hypothesis_to_concepts(hyp_id, ["concept1"], ensure_wort)

        # Query and explain
        hypotheses = memory.query_hypotheses_about("concept1")
        best = memory.get_best_hypothesis_for("concept1")
        explanation = memory.explain_hypothesis(hyp_id)
    """

    def __init__(self, driver: Driver):
        """
        Initialize hypothesis memory with Neo4j driver.

        Args:
            driver: Neo4j driver instance

        Raises:
            Neo4jConnectionError: If driver is None or connection fails
        """
        super().__init__(driver, enable_cache=False)
        logger.debug("HypothesisMemory initialized")

    def store_hypothesis(
        self,
        hypothesis_id: str,
        explanation: str,
        observations: List[str],
        strategy: str,
        confidence: float,
        scores: Dict[str, float],
        abduced_facts: List[Dict[str, Any]],
        sources: Optional[List[str]] = None,
        reasoning_trace: str = "",
    ) -> bool:
        """
        Store a hypothesis from abductive reasoning in the graph.

        Args:
            hypothesis_id: UUID of hypothesis
            explanation: Natural language explanation
            observations: List of observed phenomena
            strategy: Strategy ("template", "analogy", "causal_chain")
            confidence: Overall confidence (0.0 to 1.0)
            scores: Multi-criteria scores (coverage, simplicity, coherence, specificity)
            abduced_facts: List of abduced facts (as dicts)
            sources: List of sources/knowledge bases
            reasoning_trace: Detailed reasoning trace

        Returns:
            True if successfully stored, False on error

        Example:
            success = memory.store_hypothesis(
                hypothesis_id="uuid-1234",
                explanation="Based on similarity to X, Y must be true",
                observations=["obs1", "obs2"],
                strategy="analogy",
                confidence=0.85,
                scores={"coverage": 0.9, "simplicity": 0.8},
                abduced_facts=[{"subject": "A", "relation": "IS_A", "object": "B"}],
                sources=["knowledge_base_1"],
                reasoning_trace="Step 1: ... Step 2: ..."
            )
        """
        try:
            results = self._safe_run(
                """
                CREATE (h:Hypothesis {
                    id: $id,
                    explanation: $explanation,
                    observations: $observations,
                    strategy: $strategy,
                    confidence: $confidence,
                    scores: $scores,
                    abduced_facts: $abduced_facts,
                    sources: $sources,
                    reasoning_trace: $reasoning_trace,
                    timestamp: timestamp()
                })
                RETURN h.id AS hypothesis_id
                """,
                operation="store_hypothesis",
                id=hypothesis_id,
                explanation=explanation,
                observations=observations,
                strategy=strategy,
                confidence=confidence,
                scores=json.dumps(scores or {}),
                abduced_facts=json.dumps(abduced_facts or []),
                sources=sources or [],
                reasoning_trace=reasoning_trace,
            )

            success = len(results) > 0

            if success:
                logger.info(
                    "Hypothesis stored: %s",
                    strategy,
                    extra={
                        "hypothesis_id": hypothesis_id,
                        "confidence": confidence,
                    },
                )

            return success

        except Exception as e:
            logger.error(
                "Error storing hypothesis: %s",
                str(e)[:100],
                extra={"hypothesis_id": hypothesis_id},
                exc_info=True,
            )
            return False

    def link_hypothesis_to_observations(
        self, hypothesis_id: str, observations: List[str]
    ) -> bool:
        """
        Link a hypothesis to the observations it explains.

        Args:
            hypothesis_id: ID of hypothesis
            observations: List of observations (text strings)

        Returns:
            True if successful, False on error

        Example:
            memory.link_hypothesis_to_observations(
                "uuid-1234",
                ["The sky is blue", "Water appears blue"]
            )
        """
        if not observations:
            return False

        try:
            for obs in observations:
                self._safe_run(
                    """
                    MATCH (h:Hypothesis {id: $hyp_id})
                    MERGE (o:Observation {text: $obs})
                    MERGE (h)-[r:EXPLAINS]->(o)
                    ON CREATE SET r.linked_at = timestamp()
                    """,
                    operation="link_hypothesis_to_observation",
                    hyp_id=hypothesis_id,
                    obs=obs,
                )

            logger.debug(
                "Hypothesis linked to %d observations",
                len(observations),
                extra={"hypothesis_id": hypothesis_id[:8]},
            )

            return True

        except Exception as e:
            logger.error(
                "Error linking hypothesis to observations: %s",
                str(e)[:100],
                exc_info=True,
            )
            return False

    def link_hypothesis_to_concepts(
        self, hypothesis_id: str, concepts: List[str], ensure_wort_callback: Callable
    ) -> bool:
        """
        Link a hypothesis to the concepts it concerns.

        Args:
            hypothesis_id: ID of hypothesis
            concepts: List of concept names
            ensure_wort_callback: Callback function to call ensure_wort_und_konzept
                                  (from component_1_netzwerk_core)

        Returns:
            True if successful, False on error

        Example:
            # Assuming netzwerk_core is available:
            memory.link_hypothesis_to_concepts(
                "uuid-1234",
                ["hund", "tier"],
                ensure_wort_callback=netzwerk_core.ensure_wort_und_konzept
            )
        """
        if not concepts:
            return False

        try:
            for concept in concepts:
                # Ensure concept exists in graph
                ensure_wort_callback(concept)

                self._safe_run(
                    """
                    MATCH (h:Hypothesis {id: $hyp_id})
                    MATCH (k:Konzept {name: $concept})
                    MERGE (h)-[r:ABOUT]->(k)
                    ON CREATE SET r.linked_at = timestamp()
                    """,
                    operation="link_hypothesis_to_concept",
                    hyp_id=hypothesis_id,
                    concept=concept.lower(),
                )

            logger.debug(
                "Hypothesis linked to %d concepts",
                len(concepts),
                extra={"hypothesis_id": hypothesis_id[:8]},
            )

            return True

        except Exception as e:
            logger.error(
                "Error linking hypothesis to concepts: %s",
                str(e)[:100],
                exc_info=True,
            )
            return False

    def query_hypotheses_about(
        self,
        topic: str,
        strategy: Optional[str] = None,
        min_confidence: float = 0.0,
        limit: int = 10,
    ) -> List[Dict[str, Any]]:
        """
        Find all hypotheses about a specific topic.

        Args:
            topic: Topic to search for
            strategy: Optional - filter by strategy ("template", "analogy", "causal_chain")
            min_confidence: Minimum confidence threshold
            limit: Maximum number of results

        Returns:
            List of hypothesis dictionaries with all attributes

        Example:
            # Find all template-based hypotheses about "hund" with >80% confidence
            hypotheses = memory.query_hypotheses_about(
                topic="hund",
                strategy="template",
                min_confidence=0.8
            )
            for hyp in hypotheses:
                print(f"{hyp['explanation']} (confidence: {hyp['confidence']})")
        """
        try:
            # Build query dynamically
            where_clauses = ["h.confidence >= $min_confidence"]
            params = {
                "topic": topic.lower(),
                "min_confidence": min_confidence,
                "limit": limit,
            }

            if strategy:
                where_clauses.append("h.strategy = $strategy")
                params["strategy"] = strategy

            where_clause = " AND ".join(where_clauses)

            query = f"""
                MATCH (h:Hypothesis)-[:ABOUT]->(k:Konzept {{name: $topic}})
                WHERE {where_clause}
                RETURN h.id AS hypothesis_id,
                       h.explanation AS explanation,
                       h.observations AS observations,
                       h.strategy AS strategy,
                       h.confidence AS confidence,
                       h.scores AS scores,
                       h.abduced_facts AS abduced_facts,
                       h.sources AS sources,
                       h.reasoning_trace AS reasoning_trace,
                       h.timestamp AS timestamp
                ORDER BY h.confidence DESC, h.timestamp DESC
                LIMIT $limit
            """

            results = self._safe_run(
                query, operation="query_hypotheses_about", **params
            )

            logger.debug("Query hypotheses about '%s' -> %d found", topic, len(results))

            return results

        except Exception as e:
            logger.error(
                "Error querying hypotheses about '%s': %s",
                topic,
                str(e)[:100],
                exc_info=True,
            )
            return []

    def get_best_hypothesis_for(
        self, topic: str, strategy: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """
        Get the best hypothesis for a topic (highest confidence).

        Args:
            topic: Topic to search for
            strategy: Optional - filter by strategy

        Returns:
            Hypothesis dictionary or None

        Example:
            best = memory.get_best_hypothesis_for("hund", strategy="template")
            if best:
                print(f"Best hypothesis: {best['explanation']}")
        """
        hypotheses = self.query_hypotheses_about(
            topic=topic, strategy=strategy, limit=1
        )

        return hypotheses[0] if hypotheses else None

    def explain_hypothesis(self, hypothesis_id: str) -> str:
        """
        Generate natural language explanation of a hypothesis.

        Args:
            hypothesis_id: ID of hypothesis

        Returns:
            Human-readable explanation of the hypothesis

        Example:
            explanation = memory.explain_hypothesis("uuid-1234")
            print(explanation)
            # Output:
            # **Hypothesis (ID: uuid-123)**
            # Explanation: Based on similarity to X, Y must be true
            # Strategy: analogy
            # Confidence: 0.85
            #
            # **Scores:**
            #   - coverage: 0.90
            #   - simplicity: 0.80
            #
            # **Abduced Facts:**
            #   - A IS_A B
            #
            # **Reasoning Trace:**
            #   Step 1: ...
        """
        try:
            results = self._safe_run(
                """
                MATCH (h:Hypothesis {id: $hyp_id})
                RETURN h.explanation AS explanation,
                       h.strategy AS strategy,
                       h.confidence AS confidence,
                       h.scores AS scores,
                       h.abduced_facts AS abduced_facts,
                       h.reasoning_trace AS reasoning_trace
                """,
                operation="explain_hypothesis",
                hyp_id=hypothesis_id,
            )

            if not results:
                return f"Hypothesis {hypothesis_id[:8]} not found."

            record = results[0]

            explanation_parts = []
            explanation_parts.append(f"**Hypothesis (ID: {hypothesis_id[:8]})**")
            explanation_parts.append(f"Explanation: {record['explanation']}")
            explanation_parts.append(f"Strategy: {record['strategy']}")
            explanation_parts.append(f"Confidence: {record['confidence']:.2f}")
            explanation_parts.append("")

            # Scores
            scores = json.loads(record["scores"]) if record["scores"] else {}
            if scores:
                explanation_parts.append("**Scores:**")
                for criterion, score in scores.items():
                    explanation_parts.append(f"  - {criterion}: {score:.2f}")
                explanation_parts.append("")

            # Abduced Facts
            abduced_facts = (
                json.loads(record["abduced_facts"]) if record["abduced_facts"] else []
            )
            if abduced_facts:
                explanation_parts.append("**Abduced Facts:**")
                for fact in abduced_facts:
                    explanation_parts.append(f"  - {fact}")
                explanation_parts.append("")

            # Reasoning Trace
            if record["reasoning_trace"]:
                explanation_parts.append("**Reasoning Trace:**")
                explanation_parts.append(f"  {record['reasoning_trace']}")

            return "\n".join(explanation_parts)

        except Exception as e:
            logger.error("Error explaining hypothesis: %s", str(e)[:100], exc_info=True)
            return f"Error generating explanation: {str(e)[:100]}"
